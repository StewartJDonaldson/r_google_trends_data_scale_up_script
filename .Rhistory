rising_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "rising") %>%
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", "")
)
rising_related_query_data_cleaned
# Related query data cleaning
top_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "top") %>%
mutate(subject = as.numeric(subject))
top_related_query_data_cleaned
rising_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "rising") %>%
mutate(
subject = str_replace(subject, "Breakout", "5000"),
# subject = str_replace_all(subject,"[+,%]", "")
)
rising_related_query_data_cleaned
# Loading R libraries
library(gtrendsR)
library(tidyverse)
library(readr)
library(here)
library(lubridate)
library(data.table)
library(fable)
library(tsibble)
# Creating empty list for the loop
gtrends_data <- list()
# Reading in list of keywords I want Google Trend data for
kw_payload <- read_csv(here::here("1_raw_data/kwr_payload.csv"))
# Script Loops through each keyphrase in kwr_payload CSV and calls Google Trends API for the data
start_time <- Sys.time()
for (i in 1:nrow(kw_payload)){
gtrends_data[[i]] <- gtrends(keyword = kw_payload[[i,1]], geo = "GB", time = "today+5-y")
cat('\n',"processing",i, kw_payload[[i,1]])
}
# Works out the length of time it took the script to loop through the keyword payload and extract the data from Google Trends
end_time <- Sys.time()
time_taken <- end_time - start_time
time_taken
# Interest over time data extraction
# Google trends API returns data in a nested list. Below script extracts the interest over time data and converts it into a dataframe to amek is easier to visualise and analyse later on
interest_over_time_subset <- lapply(gtrends_data, `[[`, "interest_over_time")
interest_over_time_data <- rbindlist(interest_over_time_subset, use.names=TRUE, fill=TRUE)
interest_over_time_data
# Interest over time data cleaning
interest_over_time_data_clean <- interest_over_time_data %>%
rename(
search_interest = hits,
timespan = time,
google_product = gprop
)
interest_over_time_data_clean
# Related query data extraction
# Similiar to the interest over time data, the below code extracts the related query data from the nexted list and converts it into a dataframe
related_query_subset <- lapply(gtrends_data, `[[`, "related_queries")
related_query_data <- rbindlist(related_query_subset, use.names = TRUE, fill = TRUE)
related_query_data
# Related query data cleaning
top_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "top") %>%
mutate(subject = as.numeric(subject))
top_related_query_data_cleaned
rising_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "rising") %>%
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", "")
)
rising_related_query_data_cleaned
# Writing cleaned data to CSV
# interest_over_time_data
write_csv(interest_over_time_data_clean, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/interest_over_time_data_", format(Sys.time(),'%d_%m_%y'), ".csv"))
# related_query_data
write_csv(related_query_data, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/related_query_data_", format(Sys.time(),'%d_%m_%y'),".csv"))
# Related query data cleaning
top_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "top") %>%
mutate(subject = as.numeric(subject))
top_related_query_data_cleaned
rising_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "rising") %>%
mutate(
subject = str_replace(subject, "Breakout", "5000"),
# subject = str_replace_all(subject,"[+,%]", "")
)
rising_related_query_data_cleaned
# Related query data cleaning
top_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "top") %>%
mutate(subject = as.numeric(subject))
top_related_query_data_cleaned
rising_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "rising") %>%
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", "")
)
rising_related_query_data_cleaned
# Related query data cleaning
top_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "top") %>%
mutate(subject = as.numeric(subject))
top_related_query_data_cleaned
rising_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "rising") %>%
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
)
rising_related_query_data_cleaned
# Related query data cleaning
# Cleaning top related search data
top_related_query_data_cleaned <- related_query_data %>%
# filtering out top related search data
filter(related_queries == "top") %>%
# Converting subject column from character to numeric values
mutate(subject = as.numeric(subject)) %>%
# Cleaning column names
rename(
relative_score = subject,
most_popular_searches = value
) %>%
# Removing related_queries column
select(-related_queries)
# Cleaning rising related search data
top_related_query_data_cleaned
rising_related_query_data_cleaned <- related_query_data %>%
filter(related_queries == "rising") %>%
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
)
rising_related_query_data_cleaned
# Related query data cleaning
# Cleaning top related search data
top_related_query_data_cleaned <- related_query_data %>%
# filtering out top related search data
filter(related_queries == "top") %>%
# Converting subject column from character to numeric values
mutate(subject = as.numeric(subject)) %>%
# Cleaning column names
rename(
relative_score = subject,
most_popular_searches = value
) %>%
# Removing related_queries column
select(-related_queries)
top_related_query_data_cleaned
# Cleaning rising related search data
rising_related_query_data_cleaned <- related_query_data %>%
# filtering out rising related search data
filter(related_queries == "rising") %>%
# tidying up subject column and converting it from character to numeric value
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
) %>%
# Cleaning column names
mutate(
percentage_increase_in_search_frequency = subject,
rising_related_queries = value,
) %>%
select(-related_queries)
rising_related_query_data_cleaned
rising_related_query_data_cleaned
styler:::style_selection()
# Related query data cleaning
# Cleaning top related search data
top_related_query_data_cleaned <- related_query_data %>%
# filtering out top related search data
filter(related_queries == "top") %>%
# Converting subject column from character to numeric values
mutate(subject = as.numeric(subject)) %>%
# Cleaning column names
rename(
relative_score = subject,
most_popular_searches = value
) %>%
# Removing related_queries column
select(-related_queries)
top_related_query_data_cleaned
# Cleaning rising related search data
rising_related_query_data_cleaned <- related_query_data %>%
# filtering out rising related search data
filter(related_queries == "rising") %>%
# tidying up subject column and converting it from character to numeric value
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
) %>%
# Cleaning column names
mutate(
percentage_increase_in_search_frequency = subject,
rising_related_queries = value,
) %>%
select(-related_queries)
rising_related_query_data_cleaned
# Related query data cleaning
# Cleaning top related search data
top_related_query_data_cleaned <- related_query_data %>%
# filtering out top related search data
filter(related_queries == "top") %>%
# Converting subject column from character to numeric values
mutate(subject = as.numeric(subject)) %>%
# Cleaning column names
rename(
relative_score = subject,
most_popular_searches = value
) %>%
# Removing related_queries column
select(-related_queries)
top_related_query_data_cleaned
# Cleaning rising related search data
rising_related_query_data_cleaned <- related_query_data %>%
# filtering out rising related search data
filter(related_queries == "rising") %>%
# tidying up subject column and converting it from character to numeric value
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
) %>%
# Cleaning column names
mutate(
percentage_increase_in_search_frequency = subject,
rising_related_queries = value,
) %>%
select(-related_queries)
rising_related_query_data_cleaned
# Related query data cleaning
# Cleaning top related search data
top_related_query_data_cleaned <- related_query_data %>%
# filtering out top related search data
filter(related_queries == "top") %>%
# Converting subject column from character to numeric values
mutate(subject = as.numeric(subject)) %>%
# Cleaning column names
rename(
relative_score = subject,
most_popular_searches = value
) %>%
# Removing related_queries column
select(-related_queries)
top_related_query_data_cleaned
# Cleaning rising related search data
rising_related_query_data_cleaned <- related_query_data %>%
# filtering out rising related search data
filter(related_queries == "rising") %>%
# tidying up subject column and converting it from character to numeric value
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
) %>%
# Cleaning column names
rename(
percentage_increase_in_search_frequency = subject,
rising_related_queries = value,
) %>%
select(-related_queries)
rising_related_query_data_cleaned
# Loading R libraries
library(gtrendsR)
library(tidyverse)
library(readr)
library(here)
library(lubridate)
library(data.table)
library(fable)
library(tsibble)
# Creating empty list for the loop
gtrends_data <- list()
# Reading in list of keywords I want Google Trend data for
kw_payload <- read_csv(here::here("1_raw_data/kwr_payload.csv"))
# Script Loops through each keyphrase in kwr_payload CSV and calls Google Trends API for the data
start_time <- Sys.time()
for (i in 1:nrow(kw_payload)){
gtrends_data[[i]] <- gtrends(keyword = kw_payload[[i,1]], geo = "GB", time = "today+5-y")
cat('\n',"processing",i, kw_payload[[i,1]])
}
# Works out the length of time it took the script to loop through the keyword payload and extract the data from Google Trends
end_time <- Sys.time()
time_taken <- end_time - start_time
time_taken
# Interest over time data extraction
# Google trends API returns data in a nested list. Below script extracts the interest over time data and converts it into a dataframe to amek is easier to visualise and analyse later on
interest_over_time_subset <- lapply(gtrends_data, `[[`, "interest_over_time")
interest_over_time_data <- rbindlist(interest_over_time_subset, use.names=TRUE, fill=TRUE)
interest_over_time_data
# Interest over time data cleaning
interest_over_time_data_clean <- interest_over_time_data %>%
rename(
search_interest = hits,
timespan = time,
google_product = gprop
)
interest_over_time_data_clean
# Related query data extraction
# Similiar to the interest over time data, the below code extracts the related query data from the nexted list and converts it into a dataframe
related_query_subset <- lapply(gtrends_data, `[[`, "related_queries")
related_query_data <- rbindlist(related_query_subset, use.names = TRUE, fill = TRUE)
related_query_data
# Related query data cleaning
# Cleaning top related search data
top_related_query_data_cleaned <- related_query_data %>%
# filtering out top related search data
filter(related_queries == "top") %>%
# Converting subject column from character to numeric values
mutate(subject = as.numeric(subject)) %>%
# Cleaning column names
rename(
relative_score = subject,
most_popular_searches = value
) %>%
# Removing related_queries column
select(-related_queries)
top_related_query_data_cleaned
# Cleaning rising related search data
rising_related_query_data_cleaned <- related_query_data %>%
# filtering out rising related search data
filter(related_queries == "rising") %>%
# tidying up subject column and converting it from character to numeric value
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
) %>%
# Cleaning column names
rename(
percentage_increase_in_search_frequency = subject,
rising_related_queries = value,
) %>%
select(-related_queries)
rising_related_query_data_cleaned
# Writing cleaned data to CSV
# interest_over_time_data
write_csv(interest_over_time_data_clean, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/interest_over_time_data_", format(Sys.time(),'%d_%m_%y'), ".csv"))
# top_related_query_data_cleaned
write_csv(top_related_query_data_cleaned, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/top_related_query_data_", format(Sys.time(),'%d_%m_%y'),".csv"))
# rising_related_query_data_cleaned
write_csv(rising_related_query_data_cleaned, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/rising_related_query_data_", format(Sys.time(), '%d_%m_%y'), ".csv"))
styler:::style_selection()
styler:::style_selection()
# Loading R libraries
library(gtrendsR)
library(tidyverse)
library(readr)
library(here)
library(lubridate)
library(data.table)
# library(fable)
# library(tsibble)
# Google Trends API call
# Createempty list for the loop
gtrends_data <- list()
# Read in list of keywords you want to call the Google Trend API for
kw_payload <- read_csv(here::here("1_raw_data/kwr_payload.csv"))
# Script Loops through each keyphrase in kwr_payload CSV and calls Google Trends API for the data
start_time <- Sys.time()
for (i in 1:nrow(kw_payload)) {
gtrends_data[[i]] <- gtrends(keyword = kw_payload[[i, 1]], geo = "GB", time = "today+5-y")
cat("\n", "processing", i, kw_payload[[i, 1]])
}
# Working out the length of time the script took to loop through the keyword payload and extract the data from the Google Trends API
end_time <- Sys.time()
time_taken <- end_time - start_time
time_taken
# Interest over time data extraction
# Google trends API returns data in a nested list. The below script extracts the interest over time data and converts it into a dataframe to make it easier to visualise and analyse later on
interest_over_time_subset <- lapply(gtrends_data, `[[`, "interest_over_time")
interest_over_time_data <- rbindlist(interest_over_time_subset, use.names = TRUE, fill = TRUE)
interest_over_time_data
# Interest over time data cleaning
interest_over_time_data_clean <- interest_over_time_data %>%
# Tidying up column names
rename(
search_interest = hits,
timespan = time,
google_product = gprop
)
interest_over_time_data_clean
# Related query data extraction
# Similiar to the interest over time data, the below code extracts the related query data from the nested list and converts it into a dataframe
related_query_subset <- lapply(gtrends_data, `[[`, "related_queries")
related_query_data <- rbindlist(related_query_subset, use.names = TRUE, fill = TRUE)
related_query_data
# Related query data cleaning
# Cleaning top related search data
top_related_query_data_cleaned <- related_query_data %>%
# filtering out top related search data
filter(related_queries == "top") %>%
# Converting subject column from character to numeric values
mutate(subject = as.numeric(subject)) %>%
# Cleaning column names
rename(
relative_score = subject,
most_popular_searches = value
) %>%
# Removing related_queries column
select(-related_queries)
top_related_query_data_cleaned
# Cleaning rising related search data
rising_related_query_data_cleaned <- related_query_data %>%
# filtering out rising related search data
filter(related_queries == "rising") %>%
# tidying up subject column and converting it from character to numeric value
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
) %>%
# Cleaning column names
rename(
percentage_increase_in_search_frequency = subject,
rising_related_queries = value,
) %>%
select(-related_queries)
rising_related_query_data_cleaned
# Writing cleaned data to CSV
# interest_over_time_data
write_csv(interest_over_time_data_clean, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/interest_over_time_data_", format(Sys.time(),'%d_%m_%y'), ".csv"))
# top_related_query_data_cleaned
write_csv(top_related_query_data_cleaned, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/top_related_query_data_", format(Sys.time(),'%d_%m_%y'),".csv"))
# rising_related_query_data_cleaned
write_csv(rising_related_query_data_cleaned, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/rising_related_query_data_", format(Sys.time(), '%d_%m_%y'), ".csv"))
# Loading R libraries
library(gtrendsR)
library(tidyverse)
library(readr)
library(here)
library(lubridate)
library(data.table)
# Google Trends API call
# Createempty list for the loop
gtrends_data <- list()
# Read in list of keywords you want to call the Google Trend API for
kw_payload <- read_csv(here::here("1_raw_data/kwr_payload.csv"))
# Script Loops through each keyphrase in kwr_payload CSV and calls Google Trends API for the data
start_time <- Sys.time()
for (i in 1:nrow(kw_payload)) {
gtrends_data[[i]] <- gtrends(keyword = kw_payload[[i, 1]], geo = "GB", time = "today+5-y")
cat("\n", "processing", i, kw_payload[[i, 1]])
}
# Working out the length of time the script took to loop through the keyword payload and extract the data from the Google Trends API
end_time <- Sys.time()
time_taken <- end_time - start_time
time_taken
# Interest over time data extraction
# Google trends API returns data in a nested list. The below script extracts the interest over time data and converts it into a dataframe to make it easier to visualise and analyse later on
interest_over_time_subset <- lapply(gtrends_data, `[[`, "interest_over_time")
interest_over_time_data <- rbindlist(interest_over_time_subset, use.names = TRUE, fill = TRUE)
interest_over_time_data
# Interest over time data cleaning
interest_over_time_data_clean <- interest_over_time_data %>%
# Tidying up column names
rename(
search_interest = hits,
timespan = time,
google_product = gprop
)
interest_over_time_data_clean
# Related query data extraction
# Similiar to the interest over time data, the below code extracts the related query data from the nested list and converts it into a dataframe
related_query_subset <- lapply(gtrends_data, `[[`, "related_queries")
related_query_data <- rbindlist(related_query_subset, use.names = TRUE, fill = TRUE)
related_query_data
# Related query data cleaning
# Cleaning top related search data
top_related_query_data_cleaned <- related_query_data %>%
# filtering out top related search data
filter(related_queries == "top") %>%
# Converting subject column from character to numeric values
mutate(subject = as.numeric(subject)) %>%
# Cleaning column names
rename(
relative_score = subject,
most_popular_searches = value
) %>%
# Removing related_queries column
select(-related_queries)
top_related_query_data_cleaned
# Cleaning rising related search data
rising_related_query_data_cleaned <- related_query_data %>%
# filtering out rising related search data
filter(related_queries == "rising") %>%
# tidying up subject column and converting it from character to numeric value
mutate(
subject = str_replace(subject, "Breakout", "5000"),
subject = str_replace_all(subject,"[+,%]", ""),
subject = as.numeric(subject)
) %>%
# Cleaning column names
rename(
percentage_increase_in_search_frequency = subject,
rising_related_queries = value,
) %>%
select(-related_queries)
rising_related_query_data_cleaned
# Writing cleaned data to CSV
# interest_over_time_data
write_csv(interest_over_time_data_clean, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/interest_over_time_data_", format(Sys.time(),'%d_%m_%y'), ".csv"))
# top_related_query_data_cleaned
write_csv(top_related_query_data_cleaned, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/top_related_query_data_", format(Sys.time(),'%d_%m_%y'),".csv"))
# rising_related_query_data_cleaned
write_csv(rising_related_query_data_cleaned, paste0("~/7_personal_projects/r_google_trends_data_scale_up_script/3_cleaned_data/rising_related_query_data_", format(Sys.time(), '%d_%m_%y'), ".csv"))
